{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_clonotypes_with_umi(folder_path, heavy_output_file, light_output_file, summary_file):\n",
    "    \"\"\"\n",
    "    Processes .tsv files in the specified folder, separating IGH (heavy chain)\n",
    "    and IGK/IGL (light chain) files. Outputs:\n",
    "        - a combined CSV for heavy chain (IGH),\n",
    "        - a combined CSV for light chain (IGK + IGL → IGLC),\n",
    "        - a summary TSV of clonotype counts and UMI totals per file.\n",
    "    \"\"\"\n",
    "    heavy_data = []\n",
    "    light_data = []\n",
    "    summary_stats = []\n",
    "\n",
    "    # Traverse through all files in the folder and subfolders\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".tsv\"):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                print(f\"Processing file: {file_path}\")\n",
    "\n",
    "                data = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "                if 'nSeqCDR3' in data.columns and 'uniqueMoleculeCount' in data.columns:\n",
    "                    filtered_data = data[['nSeqCDR3', 'uniqueMoleculeCount']].dropna()\n",
    "\n",
    "                    grouped = filtered_data.groupby('nSeqCDR3').agg(\n",
    "                        Count=('nSeqCDR3', 'size'),\n",
    "                        TotalUMI=('uniqueMoleculeCount', 'sum')\n",
    "                    ).reset_index()\n",
    "\n",
    "                    grouped['Filename'] = filename\n",
    "\n",
    "                    summary_stats.append({\n",
    "                        'Filename': filename,\n",
    "                        'UniqueClonotypes': grouped.shape[0],\n",
    "                        'TotalUMI': grouped['TotalUMI'].sum(),\n",
    "                        'ChainType': 'IGH' if 'IGH' in filename else 'IGLC'\n",
    "                    })\n",
    "\n",
    "                    if 'IGH' in filename:\n",
    "                        heavy_data.append(grouped)\n",
    "                    elif 'IGK' in filename or 'IGL' in filename:\n",
    "                        light_data.append(grouped)\n",
    "                    else:\n",
    "                        print(f\"Unrecognized file type (not IGH/IGK/IGL): {filename}\")\n",
    "                else:\n",
    "                    print(f\"Warning: Required columns ('nSeqCDR3', 'uniqueMoleculeCount') not found in {filename}\")\n",
    "\n",
    "    # Save heavy chain data\n",
    "    if heavy_data:\n",
    "        heavy_df = pd.concat(heavy_data, ignore_index=True)\n",
    "        heavy_df.rename(columns={'nSeqCDR3': 'Clonotype'}, inplace=True)\n",
    "        heavy_df = heavy_df[['Filename', 'Clonotype', 'Count', 'TotalUMI']]\n",
    "        heavy_df.to_csv(heavy_output_file, index=False)\n",
    "        print(f\"Heavy chain (IGH) data saved to {heavy_output_file}\")\n",
    "    else:\n",
    "        heavy_df = None\n",
    "\n",
    "    # Save light chain data (combined IGK + IGL → IGLC)\n",
    "    if light_data:\n",
    "        light_df = pd.concat(light_data, ignore_index=True)\n",
    "        light_df.rename(columns={'nSeqCDR3': 'Clonotype'}, inplace=True)\n",
    "        light_df = light_df[['Filename', 'Clonotype', 'Count', 'TotalUMI']]\n",
    "        light_df.to_csv(light_output_file, index=False)\n",
    "        print(f\"Light chain (IGLC = IGK+IGL) data saved to {light_output_file}\")\n",
    "    else:\n",
    "        light_df = None\n",
    "\n",
    "    # Save summary statistics\n",
    "    if summary_stats:\n",
    "        summary_df = pd.DataFrame(summary_stats)\n",
    "        summary_df = summary_df[['Filename', 'ChainType', 'UniqueClonotypes', 'TotalUMI']]\n",
    "        summary_df.to_csv(summary_file, sep='\\t', index=False)\n",
    "        print(f\"Summary statistics saved to {summary_file}\")\n",
    "    else:\n",
    "        summary_df = None\n",
    "\n",
    "    return heavy_df, light_df, summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nested_folders(root_folder):\n",
    "    \"\"\"\n",
    "    Recursively traverse nested folders and process each separately.\n",
    "    For each folder containing .tsv files, generate:\n",
    "        - a CSV with per-clonotype UMI data,\n",
    "        - a summary TSV with total UMI and unique clonotypes per file,\n",
    "        - line plots of UMI distributions,\n",
    "        - a scatter plot with UMI as marker size.\n",
    "    \"\"\"\n",
    "    for folder_path, subdirs, files in os.walk(root_folder):\n",
    "        if any(file.endswith(\".tsv\") for file in files):  # Process folders containing .tsv files\n",
    "            folder_name = os.path.basename(folder_path)\n",
    "            print(f\"Processing folder: {folder_name}\")\n",
    "\n",
    "            short_string = folder_path.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")  # Normalize path to valid filename base\n",
    "\n",
    "            # Inside process_nested_folders\n",
    "            heavy_output_file = os.path.join(f\"{short_string}_IGH_heavychain.csv\")\n",
    "            light_output_file = os.path.join(f\"{short_string}_IGLC_lightchain.csv\")\n",
    "            summary_file = os.path.join(f\"{short_string}_clonotype_summary.tsv\")\n",
    "\n",
    "            heavy_df, light_df, summary_df = process_clonotypes_with_umi(\n",
    "                folder_path,\n",
    "                heavy_output_file,\n",
    "                light_output_file,\n",
    "                summary_file\n",
    "            )\n",
    "\n",
    "\n",
    "# Define the root folder\n",
    "root_folder = \"MGI\"  # Replace with the path to your root folder\n",
    "\n",
    "# Call the function to process nested folders\n",
    "process_nested_folders(root_folder)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
